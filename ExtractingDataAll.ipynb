{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1685807d-1933-4498-bfa6-5d12c351d2d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "009b4e6b-6e22-4291-95f5-bf7609edc3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (to_timestamp, year, month, col, avg, month, dayofmonth, hour, minute, second, date_format, to_date, sum as _sum)\n",
    "from pyspark.sql.functions import when, udf\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b74da121-47f9-461c-9a49-899d95c31d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/07/24 14:10:11 WARN Utils: Your hostname, Anduril, resolves to a loopback address: 127.0.1.1; using 172.16.81.227 instead (on interface wlo1)\n",
      "25/07/24 14:10:11 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/07/24 14:10:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/07/24 14:10:12 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark=SparkSession.builder.appName(\"Cabanuelas1\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ab57f82-0861-4ea9-bac3-0c82f24a521b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "var=\"TEMP\"\n",
    "T=spark.read.csv(\"IDEAM_Temperatura.csv\",header=True,inferSchema=True)\n",
    "meth=avg\n",
    "#var=\"HUMI\"\n",
    "#T=spark.read.csv(\"IDEAM_Humedad_del_Aire_2_metros.csv\",header=True,inferSchema=True)\n",
    "#meth=avg\n",
    "#var=\"RAIN\"\n",
    "#T=spark.read.csv(\"IDEAM_Precipitacion.csv\",header=True,inferSchema=True)\n",
    "#meth=_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c669aaf4-b81f-44e4-8bf1-e5f71e32d400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CodigoEstacion: long (nullable = true)\n",
      " |-- CodigoSensor: integer (nullable = true)\n",
      " |-- FechaObservacion: string (nullable = true)\n",
      " |-- ValorObservado: double (nullable = true)\n",
      " |-- NombreEstacion: string (nullable = true)\n",
      " |-- Departamento: string (nullable = true)\n",
      " |-- Municipio: string (nullable = true)\n",
      " |-- ZonaHidrografica: string (nullable = true)\n",
      " |-- Latitud: double (nullable = true)\n",
      " |-- Longitud: double (nullable = true)\n",
      " |-- DescripcionSensor: string (nullable = true)\n",
      " |-- UnidadMedida: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "T.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "991049e9-c76e-443e-8db8-bac1c9088d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+--------------------+--------------+--------------------+------------+-----------+--------------------+-----------+------------+-----------------+------------+\n",
      "|CodigoEstacion|CodigoSensor|    FechaObservacion|ValorObservado|      NombreEstacion|Departamento|  Municipio|    ZonaHidrografica|    Latitud|    Longitud|DescripcionSensor|UnidadMedida|\n",
      "+--------------+------------+--------------------+--------------+--------------------+------------+-----------+--------------------+-----------+------------+-----------------+------------+\n",
      "|      25025280|          68|11/14/2013 11:00:...|          30.0|EL TESORO IDEAM  ...|       SUCRE|     MORROA|BAJO MAGDALENA- C...|9.357083333|   -75.28925|    Temp Aire 2 m|          °C|\n",
      "|      24035370|          68|08/25/2013 11:00:...|          11.5|     EL ESPINO - AUT|      BOYACÁ|  EL ESPINO|            SOGAMOSO|6.506722222|-72.45266667|    Temp Aire 2 m|          °C|\n",
      "|      21206920|          68|10/08/2018 02:00:...|          10.5|  VILLA TERESA - AUT|      BOGOTA|BOGOTA, D.C|      ALTO MAGDALENA|       4.35|      -74.15|    Temp Aire 2 m|          °C|\n",
      "|    2120000106|          68|01/21/2019 10:54:...|         10.54|  GRAN BRETAÑA - AUT| BOGOTA D.C.|BOGOTA, D.C|      ALTO MAGDALENA|      4.512|     -74.164|    Temp Aire 2 m|          °C|\n",
      "|      21201980|          68|05/15/2016 11:40:...|          15.1|CERRO GUADALUPE -...| BOGOTA D.C.|BOGOTA, D.C|      ALTO MAGDALENA|      4.567|      -74.05|    Temp Aire 2 m|          °C|\n",
      "+--------------+------------+--------------------+--------------+--------------------+------------+-----------+--------------------+-----------+------------+-----------------+------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "T.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "decc643b-2d3c-4518-90b2-9a8361cfa3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "map1={\"SANTANDER\":\"SANTANDER\",\"CÓRDOBA\":\"CORDOBA\",\"NARIÑO\":\"NARINO\",\"BOYACÁ\":\"BOYACA\",\"CAQUETA\":\"CAQUETA\",\"CASANARE\":\"CASANARE\",\n",
    "      \"META\":\"META\",\"AMAZONAS\":\"AMAZONAS\",\"GUAINÍA\":\"GUAINIA\",\"GUAVIARE\":\"GUAVIARE\",\"CAUCA\":\"CAUCA\",\"ANTIOQUIA\":\"ANTIOQUIA\",\n",
    "      \"BOLÍVAR\":\"BOLIVAR\",\"CHOCO\":\"CHOCO\",\"CALDAS\":\"CALDAS\",\"ATLÁNTICO\":\"ATLANTICO\",\"VALLE DEL CAUCA\":\"VALLE DEL CAUCA\",\n",
    "      \"CUNDINAMARCA\":\"CUNDINAMARCA\",\"LA GUAJIRA\":\"LA GUAJIRA\",\"NARINO\":\"NARINO\",\"TOLIMA\":\"TOLIMA\",\"ARAUCA\":\"ARAUCA\",\n",
    "      \"NORTE DE SANTANDER\":\"NORTE DE SANTANDER\",\"SAN ANDRÉS PROVIDENCIA\":\"SAN ANDRES PROVIDENCIA\",\"BOGOTA\":\"BOGOTA\",\"HUILA\":\"HUILA\",\n",
    "      \"SUCRE\":\"SUCRE\",\"ATLANTICO\":\"ATLANTICO\",\"CHOCÓ\":\"CHOCO\",\"BOLIVAR\":\"BOLIVAR\",\"BOGOTA D.C.\":\"BOGOTA\",\"RISARALDA\":\"RISARALDA\",\"PUTUMAYO\":\"PUTUMAYO\",\n",
    "      \"MAGDALENA\":\"MAGDALENA\",\"QUINDÍO\":\"QUINDIO\",\"CORDOBA\":\"CORDOBA\",\"CESAR\":\"CESAR\",\"VAUPÉS\":\"VAUPES\",\"VICHADA\":\"VICHADA\",\n",
    "      \"ARCHIPIELAGO DE SAN ANDRES, PROVIDENCIA Y SANTA CATALINA\":\"SAN ANDRES PROVIDENCIA\",\"BOGOTÁ\":\"BOGOTA\",\"CAQUETÁ\":\"CAQUETA\",\n",
    "      \"ARCHIPIELAGO DE SAN ANDRES PROVIDENCIA Y SANTA CATALINA\":\"SAN ANDRES PROVIDENCIA\",\"ARCHIPIELAGO DE SAN ANDRES PROVIDENCIA Y SANTA CATALINA\":\"SAN ANDRES PROVIDENCIA\",\n",
    "     \"ARCHIPIÉLAGO DE SAN ANDRES PROVIDENCIA Y SANTA CATALINA\":\"SAN ANDRES PROVIDENCIA\"}\n",
    "\n",
    "mapping_bc=spark.sparkContext.broadcast(map1)\n",
    "def map_col(x):\n",
    "    return mapping_bc.value.get(x,x)\n",
    "\n",
    "map_col_udf=udf(map_col,StringType())\n",
    "T=T.withColumn(\"Departamento\",map_col_udf(\"Departamento\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "848806da-dcea-4bc0-8ff0-087c6d390698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Fecha24h: string (nullable = true)\n",
      " |-- ValorObservado: double (nullable = true)\n",
      " |-- Departamento: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+------------+\n",
      "|Fecha24h           |ValorObservado|Departamento|\n",
      "+-------------------+--------------+------------+\n",
      "|2013-11-14 11:00:00|30.0          |SUCRE       |\n",
      "|2013-08-25 11:00:00|11.5          |BOYACA      |\n",
      "|2018-10-08 14:00:00|10.5          |BOGOTA      |\n",
      "|2019-01-21 10:54:00|10.54         |BOGOTA      |\n",
      "|2016-05-15 11:40:00|15.1          |BOGOTA      |\n",
      "+-------------------+--------------+------------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# 1) Selecciono sólo las columnas que necesito\n",
    "df1 = T.select(\n",
    "    col(\"FechaObservacion\"),\n",
    "    col(\"Departamento\"),\n",
    "    col(\"ValorObservado\")\n",
    ")\n",
    "\n",
    "# 2) Parseo FechaObservacion y la convierto a Timestamp 24 h\n",
    "#    – to_timestamp(..., \"MM/dd/yyyy hh:mm:ss a\") hace el parseo AM/PM\n",
    "#    – date_format(..., \"yyyy-MM-dd HH:mm:ss\") la formatea como string 24 h\n",
    "df2 = df1.withColumn(\n",
    "    \"Fecha24h\",\n",
    "    date_format(\n",
    "        to_timestamp(col(\"FechaObservacion\"), \"MM/dd/yyyy hh:mm:ss a\"),\n",
    "        \"yyyy-MM-dd HH:mm:ss\"\n",
    "    )\n",
    ").drop(\"FechaObservacion\")  # opcional: elimino la columna original\n",
    "\n",
    "# 3) Reordeno columnas si quieres:\n",
    "df2 = df2.select(\"Fecha24h\", \"ValorObservado\", \"Departamento\")\n",
    "\n",
    "# 4) Compruebo\n",
    "df2.printSchema()\n",
    "df2.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae6a3ef9-0e11-440b-8011-0676560a1e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Creamos columna de tipo Timestamp y luego columna de solo Date\n",
    "df3 = (\n",
    "    df2\n",
    "    .withColumn(\n",
    "        \"ts\",\n",
    "        to_timestamp(col(\"Fecha24h\"), \"yyyy-MM-dd HH:mm:ss\")\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"date\",\n",
    "        to_date(col(\"ts\"))      # extrae YYYY-MM-DD\n",
    "    )\n",
    ")\n",
    "\n",
    "# 3) Agrupamos por Departamento y date, sumando ValorObservado\n",
    "daily_dept = (\n",
    "    df3\n",
    "    .groupBy(\"Departamento\", \"date\")\n",
    "    .agg(\n",
    "        meth(col(\"ValorObservado\")).alias(\"sum_ValorObservado\")\n",
    "    )\n",
    "    .orderBy(\"Departamento\", \"date\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abdb1e36-ad30-4ff4-9384-179f6f9b3ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "daily_dept.write.option(\"header\", \"true\").csv(\"{}_{}_ano_depto\".format(meth,var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bc4983-45a0-4f21-b7fd-80efffa12987",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
